{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MRCNN_custom.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4Hjjc40apLpd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamconrad7/Mask_RCNN/blob/main/Copy_of_MRCNN_custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGiIgx6PQR_i"
      },
      "source": [
        "#Mask R-CNN instance segmentation with custom dataset in Google Colab\n",
        "Jupyter notebook providing steps to train a **Matterport Mask R-CNN** model with custom dataset.\n",
        "\n",
        "It runs in [Google Colab](https://colab.research.google.com/) using [Matterport framework](https://github.com/matterport/Mask_RCNN) with TensorFlow backend.\n",
        "\n",
        "**Requirements are only dataset images and annotations file.**\n",
        "\n",
        "**Colab Runtime type: Python3, GPU enabled.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umEL6-vlmXmj"
      },
      "source": [
        "#Making Dataset\n",
        "I generated dataset annotations with [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/).\n",
        "\n",
        "Notebook train a model for one class object detection. It is possible to slightly modify notebook to train model for multiple classes.\n",
        "\n",
        "Before running notebook, we need to create dataset:\n",
        "\n",
        "\n",
        "1.   Collect various pictures of objects to detect\n",
        "3.   Create annotation files in VGG\n",
        "4.   Create image.zip file having structure defined below\n",
        "5.   Upload the zip file in your Google Drive\n",
        "\n",
        "Zip file structure:\n",
        "```\n",
        "images.zip\n",
        "|- \"train\" directory\n",
        "  |- jpg image files of training data\n",
        "  |- \"via_region_data.json\" annotations file of training data\n",
        "|- \"val\" directory\n",
        "  |- jpg image files of validation data\n",
        "  |- \"via_region_data.json\" annotations file of validation data\n",
        "```\n",
        "Check my image.zip file as dataset example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywU9FM5qn6Wx"
      },
      "source": [
        "#Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Wtm53bG7xW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a714e42c-c68c-4546-f3f0-22d2607143db"
      },
      "source": [
        "%cd\n",
        "  \n",
        "!git clone --quiet https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZY2h5buS9xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c993eaa7-1f5e-44d7-c968-0b63ee5e93ab"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "\n",
        "!pip install -q PyDrive\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Requirement already satisfied: tensorflow>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.4.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.4.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 10)) (1.5.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.7.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (57.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
            "Collecting ipyparallel; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e9/03a9189eb39276396309faf28bf833b4328befe4513bbf375b811a36a076/ipyparallel-6.3.0-py3-none-any.whl (199kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.10.1)\n",
            "Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Collecting nose>=0.10.1; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n",
            "Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.6.3)\n",
            "Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.3.1)\n",
            "Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.6.1)\n",
            "Requirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.1.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.3.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.3.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (22.1.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.7.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.9.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.17.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.4)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (21.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.11.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (4.6.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.5.0)\n",
            "Installing collected packages: ipyparallel, nose\n",
            "Successfully installed ipyparallel-6.3.0 nose-1.3.7\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating mask_rcnn.egg-info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/mrcnn\n",
            "copying mrcnn/parallel_model.py -> build/lib/mrcnn\n",
            "copying mrcnn/utils.py -> build/lib/mrcnn\n",
            "copying mrcnn/model.py -> build/lib/mrcnn\n",
            "copying mrcnn/__init__.py -> build/lib/mrcnn\n",
            "copying mrcnn/config.py -> build/lib/mrcnn\n",
            "copying mrcnn/visualize.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.7.egg\n",
            "Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding mask-rcnn 2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC6sZTwOIS6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8679da50-b94d-4108-aad2-a5ae48fd7a26"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y\n",
        "\n",
        "# !pip install tensorflow==1.13.1\n",
        "!pip install tensorflow-gpu==1.13.1\n",
        "# !pip install --upgrade --ignore-installed tensorflow-gpu\n",
        "!pip install keras==2.0.8\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.0.8:\n",
            "  Successfully uninstalled Keras-2.0.8\n",
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "\u001b[33mWARNING: Skipping keras-vis as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Uninstalling h5py-2.10.0:\n",
            "  Successfully uninstalled h5py-2.10.0\n",
            "Requirement already satisfied: tensorflow-gpu==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.34.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.13.0)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Collecting h5py\n",
            "  Using cached https://files.pythonhosted.org/packages/e5/8e/c36cb359b185d56af8fe22a8a6db58af1e98be902677d032b87018763dd0/h5py-3.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n",
            "Installing collected packages: keras-preprocessing, h5py\n",
            "Successfully installed h5py-3.3.0 keras-preprocessing-1.1.2\n",
            "Collecting keras==2.0.8\n",
            "  Using cached https://files.pythonhosted.org/packages/67/3f/d117d6e48b19fb9589369f4bdbe883aa88943f8bb4a850559ea5c546fefb/Keras-2.0.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (3.13)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.0.8\n",
            "Collecting h5py==2.10.0\n",
            "  Using cached https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Found existing installation: h5py 3.3.0\n",
            "    Uninstalling h5py-3.3.0:\n",
            "      Successfully uninstalled h5py-3.3.0\n",
            "Successfully installed h5py-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zZg68_koGU7"
      },
      "source": [
        "#Download and extract dataset\n",
        "Update fileId variable with Google Drive id of your image.zip dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3KxhAII1PDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82399233-c93d-4b7e-f576-89dd98402754"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "\n",
        "\n",
        "# fileId = '1p11kagop07-LyNyTIQ5_bDHx6I2TSDN9'\n",
        "fileId = '1w7uzjCVXa00XbxWYbiGwo9g0cqgG82Vc'\n",
        "# 1m_CviMKnVHaDbN1tUVyw3aelMO-kFGXq\n",
        "\n",
        "# .zip\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# 1d4n3IcshsJaTpK8iNdc5z3kPKtWXvuCV\n",
        "\n",
        "# os.makedirs('dataset')\n",
        "# os.chdir('dataset')\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# file_list = drive.ListFile().GetList()\n",
        "# for f in file_list:\n",
        "#   print(f)\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "Extracted zip file 1w7uzjCVXa00XbxWYbiGwo9g0cqgG82Vc.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul-dMqZdOchP"
      },
      "source": [
        "!rm -rf dataset/\n",
        "!rm -rf dataset/train/\n",
        "!rm -rf dataset/val/\n",
        "# !rm -rf rcnn_data/\n",
        "\n",
        "\n",
        "# !pwd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQcB6EenFW7D"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hjjc40apLpd"
      },
      "source": [
        "#Edit settings file\n",
        "*  find and replace occurrences of \"balloon\" and \"Balloon\" with name of your object\n",
        "*  set epochs number\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SVHFnl5Hwe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1322ecf-d7f8-4965-9077-3bba3b7a4d2b"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
        "# reload(dog)\n",
        "\n",
        "!cp ~/Mask_RCNN/samples/balloon/balloon.py ./dog.py\n",
        "\n",
        "!sed -i -- 's/balloon/dog/g' dog.py\n",
        "!sed -i -- 's/Balloon/Dog/g' dog.py\n",
        "!sed -i -- 's/epochs=30/epochs=10/g' dog.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjmxrVOwq0rC"
      },
      "source": [
        "#Train model\n",
        "Pretrained weights options are COCO, ImageNet or a model trained before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGrimv2Xuf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e59d46-4ce4-4d23-d4e8-54a9184d0308"
      },
      "source": [
        "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
        "\n",
        "# import dog\n",
        "reload(dog)\n",
        "%cd ~/Mask_RCNN\n",
        "\n",
        "# import dog\n",
        "# reload(dog)\n",
        "\n",
        "!python dog.py train --dataset=dataset/ --weights=coco"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/Mask_RCNN\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n",
            "Weights:  coco\n",
            "Dataset:  dataset/\n",
            "Logs:  /logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           dog\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "Loading weights  /mask_rcnn_coco.h5\n",
            "2021-07-18 06:00:28.622884: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-07-18 06:00:28.627835: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-07-18 06:00:28.628108: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x561be682d440 executing computations on platform Host. Devices:\n",
            "2021-07-18 06:00:28.628148: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-07-18 06:00:28.641159: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-07-18 06:00:28.641212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:148] kernel driver does not appear to be running on this host (320c604ff11e): /proc/driver/nvidia/version does not exist\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /logs/dog20210718T0600/mask_rcnn_dog_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "Epoch 1/10\n",
            "ERROR:root:Error processing image {'id': 'crop_81.png', 'source': 'dog', 'path': 'dataset/train/crop_81.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 417, 'cy': 255, 'r': 12}, {'name': 'circle', 'cx': 505, 'cy': 253, 'r': 14.016}, {'name': 'circle', 'cx': 200, 'cy': 35, 'r': 16}, {'name': 'circle', 'cx': 380, 'cy': 103, 'r': 12}, {'name': 'circle', 'cx': 442, 'cy': 437, 'r': 13}, {'name': 'circle', 'cx': 149, 'cy': 89, 'r': 14}, {'name': 'circle', 'cx': 422, 'cy': 173, 'r': 15}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_120.png', 'source': 'dog', 'path': 'dataset/train/crop_120.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 330, 'cy': 40, 'r': 9}, {'name': 'circle', 'cx': 505, 'cy': 124, 'r': 11}, {'name': 'circle', 'cx': 82, 'cy': 165, 'r': 15}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "2021-07-18 06:00:52.137943: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node proposal_targets/strided_slice. Error: ValidateStridedSliceOp returned partial shapes [1,?,?] and [?,?]\n",
            "2021-07-18 06:00:52.138080: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node proposal_targets/strided_slice_37. Error: ValidateStridedSliceOp returned partial shapes [1,?,?] and [?,?]\n",
            "2021-07-18 06:00:59.723366: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node proposal_targets/strided_slice. Error: ValidateStridedSliceOp returned partial shapes [1,?,?] and [?,?]\n",
            "2021-07-18 06:00:59.723471: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node proposal_targets/strided_slice_37. Error: ValidateStridedSliceOp returned partial shapes [1,?,?] and [?,?]\n",
            "ERROR:root:Error processing image {'id': 'crop_50.png', 'source': 'dog', 'path': 'dataset/train/crop_50.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 12, 'cy': 395, 'r': 14}, {'name': 'circle', 'cx': 263, 'cy': 362, 'r': 9}, {'name': 'circle', 'cx': 81, 'cy': 227, 'r': 12}, {'name': 'circle', 'cx': 141, 'cy': 504, 'r': 16}, {'name': 'circle', 'cx': 83, 'cy': 442, 'r': 13}, {'name': 'circle', 'cx': 315, 'cy': 430, 'r': 14}, {'name': 'circle', 'cx': 394, 'cy': 173, 'r': 9}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 0 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_195.png', 'source': 'dog', 'path': 'dataset/train/crop_195.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 13, 'cy': 359, 'r': 11}, {'name': 'circle', 'cx': 501, 'cy': 329, 'r': 15}, {'name': 'circle', 'cx': 311, 'cy': 205, 'r': 7}, {'name': 'circle', 'cx': 182, 'cy': 81, 'r': 12}, {'name': 'circle', 'cx': 259, 'cy': 46, 'r': 9}, {'name': 'circle', 'cx': 41, 'cy': 478, 'r': 15}, {'name': 'circle', 'cx': 427, 'cy': 370, 'r': 10}, {'name': 'circle', 'cx': 233, 'cy': 347, 'r': 9}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_50.png', 'source': 'dog', 'path': 'dataset/train/crop_50.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 12, 'cy': 395, 'r': 14}, {'name': 'circle', 'cx': 263, 'cy': 362, 'r': 9}, {'name': 'circle', 'cx': 81, 'cy': 227, 'r': 12}, {'name': 'circle', 'cx': 141, 'cy': 504, 'r': 16}, {'name': 'circle', 'cx': 83, 'cy': 442, 'r': 13}, {'name': 'circle', 'cx': 315, 'cy': 430, 'r': 14}, {'name': 'circle', 'cx': 394, 'cy': 173, 'r': 9}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 0 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_120.png', 'source': 'dog', 'path': 'dataset/train/crop_120.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 330, 'cy': 40, 'r': 9}, {'name': 'circle', 'cx': 505, 'cy': 124, 'r': 11}, {'name': 'circle', 'cx': 82, 'cy': 165, 'r': 15}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_81.png', 'source': 'dog', 'path': 'dataset/train/crop_81.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 417, 'cy': 255, 'r': 12}, {'name': 'circle', 'cx': 505, 'cy': 253, 'r': 14.016}, {'name': 'circle', 'cx': 200, 'cy': 35, 'r': 16}, {'name': 'circle', 'cx': 380, 'cy': 103, 'r': 12}, {'name': 'circle', 'cx': 442, 'cy': 437, 'r': 13}, {'name': 'circle', 'cx': 149, 'cy': 89, 'r': 14}, {'name': 'circle', 'cx': 422, 'cy': 173, 'r': 15}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_195.png', 'source': 'dog', 'path': 'dataset/train/crop_195.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 13, 'cy': 359, 'r': 11}, {'name': 'circle', 'cx': 501, 'cy': 329, 'r': 15}, {'name': 'circle', 'cx': 311, 'cy': 205, 'r': 7}, {'name': 'circle', 'cx': 182, 'cy': 81, 'r': 12}, {'name': 'circle', 'cx': 259, 'cy': 46, 'r': 9}, {'name': 'circle', 'cx': 41, 'cy': 478, 'r': 15}, {'name': 'circle', 'cx': 427, 'cy': 370, 'r': 10}, {'name': 'circle', 'cx': 233, 'cy': 347, 'r': 9}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "ERROR:root:Error processing image {'id': 'crop_81.png', 'source': 'dog', 'path': 'dataset/train/crop_81.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 417, 'cy': 255, 'r': 12}, {'name': 'circle', 'cx': 505, 'cy': 253, 'r': 14.016}, {'name': 'circle', 'cx': 200, 'cy': 35, 'r': 16}, {'name': 'circle', 'cx': 380, 'cy': 103, 'r': 12}, {'name': 'circle', 'cx': 442, 'cy': 437, 'r': 13}, {'name': 'circle', 'cx': 149, 'cy': 89, 'r': 14}, {'name': 'circle', 'cx': 422, 'cy': 173, 'r': 15}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "2021-07-18 06:02:01.478480: W tensorflow/core/framework/allocator.cc:124] Allocation of 268435456 exceeds 10% of system memory.\n",
            "ERROR:root:Error processing image {'id': 'crop_81.png', 'source': 'dog', 'path': 'dataset/train/crop_81.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 417, 'cy': 255, 'r': 12}, {'name': 'circle', 'cx': 505, 'cy': 253, 'r': 14.016}, {'name': 'circle', 'cx': 200, 'cy': 35, 'r': 16}, {'name': 'circle', 'cx': 380, 'cy': 103, 'r': 12}, {'name': 'circle', 'cx': 442, 'cy': 437, 'r': 13}, {'name': 'circle', 'cx': 149, 'cy': 89, 'r': 14}, {'name': 'circle', 'cx': 422, 'cy': 173, 'r': 15}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 1 with size 512\n",
            "2021-07-18 06:02:13.454920: W tensorflow/core/framework/allocator.cc:124] Allocation of 268435456 exceeds 10% of system memory.\n",
            "2021-07-18 06:02:15.108618: W tensorflow/core/framework/allocator.cc:124] Allocation of 268435456 exceeds 10% of system memory.\n",
            "2021-07-18 06:02:16.618440: W tensorflow/core/framework/allocator.cc:124] Allocation of 603979776 exceeds 10% of system memory.\n",
            "2021-07-18 06:02:34.876625: W tensorflow/core/framework/allocator.cc:124] Allocation of 603979776 exceeds 10% of system memory.\n",
            "  4/100 [>.............................] - ETA: 14451s - loss: 2.6966 - rpn_class_loss: 0.2795 - rpn_bbox_loss: 0.2473 - mrcnn_class_loss: 0.3368 - mrcnn_bbox_loss: 0.9062 - mrcnn_mask_loss: 0.9268ERROR:root:Error processing image {'id': 'crop_50.png', 'source': 'dog', 'path': 'dataset/train/crop_50.png', 'width': 512, 'height': 512, 'polygons': [{'name': 'circle', 'cx': 12, 'cy': 395, 'r': 14}, {'name': 'circle', 'cx': 263, 'cy': 362, 'r': 9}, {'name': 'circle', 'cx': 81, 'cy': 227, 'r': 12}, {'name': 'circle', 'cx': 141, 'cy': 504, 'r': 16}, {'name': 'circle', 'cx': 83, 'cy': 442, 'r': 13}, {'name': 'circle', 'cx': 315, 'cy': 430, 'r': 14}, {'name': 'circle', 'cx': 394, 'cy': 173, 'r': 9}]}\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"dog.py\", line 166, in load_mask\n",
            "    mask[rr, cc, i] = 1\n",
            "IndexError: index 512 is out of bounds for axis 0 with size 512\n",
            "  5/100 [>.............................] - ETA: 14065s - loss: 3.3811 - rpn_class_loss: 0.5110 - rpn_bbox_loss: 0.7673 - mrcnn_class_loss: 0.3267 - mrcnn_bbox_loss: 0.8770 - mrcnn_mask_loss: 0.8991Traceback (most recent call last):\n",
            "  File \"dog.py\", line 366, in <module>\n",
            "    train(model)\n",
            "  File \"dog.py\", line 201, in train\n",
            "    layers='heads')\n",
            "  File \"/root/Mask_RCNN/mrcnn/model.py\", line 2374, in train\n",
            "    use_multiprocessing=True,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 2011, in fit_generator\n",
            "    generator_output = next(output_generator)\n",
            "StopIteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laqF3Tihrqs3"
      },
      "source": [
        "#Run inference on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o7dH-mRX2A0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "f182109a-41fb-4f4c-e239-3c9e83f91992"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import skimage\n",
        "import glob\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "import dog\n",
        "reload(dog)\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "\n",
        "custom_WEIGHTS_PATH = sorted(glob.glob(\"/logs/*/mask_rcnn_*.h5\"))[-1]\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "config = dog.DogConfig()\n",
        "custom_DIR = os.path.join(ROOT_DIR, \"dataset\")\n",
        "\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\"\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax\n",
        "  \n",
        "# Load validation dataset\n",
        "dataset = dog.DogDataset()\n",
        "dataset.load_dog(custom_DIR, \"val\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
        "\n",
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "\n",
        "# load the last model you trained\n",
        "# weights_path = model.find_last()[1]\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", custom_WEIGHTS_PATH)\n",
        "model.load_weights(custom_WEIGHTS_PATH, by_name=True)\n",
        "\n",
        "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
        "reload(visualize)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b22a71f6e390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To find local version of the library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mcustom_WEIGHTS_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/logs/*/mask_rcnn_*.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7iSzccTL9hM"
      },
      "source": [
        "#image_id = random.choice(dataset.image_ids)\n",
        "for image_id in dataset.image_ids:\n",
        "  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "  info = dataset.image_info[image_id]\n",
        "  print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                         dataset.image_reference(image_id)))\n",
        "\n",
        "  # Run object detection\n",
        "  results = model.detect([image], verbose=1)\n",
        "\n",
        "  # Display results\n",
        "  ax = get_ax(1)\n",
        "  r = results[0]\n",
        "  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                              dataset.class_names, r['scores'], ax=ax,\n",
        "                              title=\"Predictions\")\n",
        "  log(\"gt_class_id\", gt_class_id)\n",
        "  log(\"gt_bbox\", gt_bbox)\n",
        "  log(\"gt_mask\", gt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}